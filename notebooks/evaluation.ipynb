{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b1213a8dbc01a2bbcdeb4e02d2d3f5411d6dec13eff8952fed902e4513bf8e24"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# WESAD Validation Notebook for FLIRT\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/fefespinola/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib; matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.autonotebook import trange\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import utils, model_selection, metrics\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import List\n",
    "import lightgbm as lgb\n",
    "import glob2\n",
    "import os \n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/home/fefespinola/ETHZ_Fall_2020/flirt-1')\n",
    "import flirt.simple"
   ]
  },
  {
   "source": [
    "The following function retrieves all HRV, EDA and ACC features per subject using the FLIRT pipeline\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c9c2e5945b79>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c9c2e5945b79>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The following function retrieves all HRV, EDA and ACC features per subject using the FLIRT pipeline\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_per_subject(path, window_length):\n",
    "    features = flirt.simple.get_features_for_empatica_archive(zip_file_path = path,\n",
    "                                      window_length = window_length,\n",
    "                                      window_step_size = 0.25,\n",
    "                                      hrv_features = False,\n",
    "                                      eda_features = True,\n",
    "                                      acc_features = False,\n",
    "                                      bvp_features = False,\n",
    "                                      temp_features = False,\n",
    "                                      debug = True)\n",
    "    return features"
   ]
  },
  {
   "source": [
    "The following function determines the time offsets of the start and end of each relevant analysis period (baseline, stress, amusement). These offsets are combined with the timestamp stating the start of recording, to determine the absolute timestamps of the sections of interest for each subject. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label_timestamps(csv_path, StartingTime):\n",
    "\n",
    "    ID = csv_path.split('/', 3)[2]\n",
    "    df_timestamp = pd.read_csv(glob2.glob('project_data/WESAD/' + ID + '/*quest.csv')[0], delimiter = ';', header = 1).iloc[:2, :].dropna(axis = 1)\n",
    "    print('===================================')\n",
    "    print('Printing the timestamp for {0}'.format(ID))\n",
    "    print('===================================')\n",
    "    print(df_timestamp.head())\n",
    "    \n",
    "    # Start/End of experiment periods\n",
    "    print('\\nStart of the baseline: ' + str(df_timestamp['Base'][0]))\n",
    "    print('End of the baseline: ' + str(df_timestamp['Base'][1]))\n",
    "    print('Start of the fun: ' + str(df_timestamp['Fun'][0]))\n",
    "    print('End of the fun: ' + str(df_timestamp['Fun'][1]))\n",
    "    print('Start of the stress: ' + str(df_timestamp['TSST'][0]))\n",
    "    print('End of the stress: ' + str(df_timestamp['TSST'][1]))\n",
    "    \n",
    "    # Get start and end time and assign label into a dict\n",
    "    lab_dict = {'Base':0, 'TSST':1, 'Fun':2}\n",
    "    labels_times_dict = {}\n",
    "    for mode in df_timestamp.columns.tolist():\n",
    "        print('mode', mode)\n",
    "        if mode=='Base' or mode=='Fun' or mode=='TSST':\n",
    "            labels_times_dict[mode] = [StartingTime + timedelta(minutes = int(str(df_timestamp[mode][0]).split(\".\")[0]))+ timedelta                                         (seconds = int(str(df_timestamp[mode][0]).split(\".\")[1])), \n",
    "                                    StartingTime + timedelta(minutes = int(str(df_timestamp[mode][1]).split(\".\")[0])) + timedelta                                           (seconds = int(str(df_timestamp[mode][1]).split(\".\")[1])), lab_dict[mode]]\n",
    "            \n",
    "            #labels_times_dict[mode] = [StartingTime + timedelta(minutes = float(df_timestamp[mode][0])), \n",
    "                                  #StartingTime + timedelta(minutes = float(df_timestamp[mode][1])), lab_dict[mode]]\n",
    "        \n",
    "    return labels_times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def find_label_start_time(csv_path):\n",
    "    ID = csv_path.split('/', 3)[2]\n",
    "    timestamp = open(glob2.glob('project_data/WESAD/' + ID + '/*respiban.txt')[0], \"r\")\n",
    "    for i in range(2):\n",
    "        line = (timestamp.readline())\n",
    "        line = line.strip()[2:]\n",
    "        if i==1:\n",
    "            dict = ast.literal_eval(line)\n",
    "            start_time_str = dict['00:07:80:D8:AB:58']['time']\n",
    "            date_str = dict['00:07:80:D8:AB:58']['date']\n",
    "            datetime_str = date_str + \" \" + start_time_str\n",
    "            #print(datetime_str)\n",
    "            date_time_obj = parse(datetime_str)\n",
    "            #print(date_time_obj)\n",
    "            start_time = date_time_obj\n",
    "            utc_time = start_time - timedelta(hours=2)\n",
    "\n",
    "    timestamp.close()\n",
    "\n",
    "    #df_timestamp = pd.read_table(glob2.glob('project_data/WESAD/' + ID + '/*respiban.txt')[0], delim_whitespace=True)#.iloc[:2, :].dropna(axis = 1)\n",
    "    print('===================================')\n",
    "    print('Printing the timestamp for {0}'.format(ID))\n",
    "    print('===================================')\n",
    "    #print(df_timestamp.head())\n",
    "    return utc_time"
   ]
  },
  {
   "source": [
    "Plots the training and validation classification metric evolution with the number of iterations. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===================================\nPrinting the timestamp for S10\n===================================\n2017-07-25 07:25:01\n===================================\nPrinting the timestamp for S11\n===================================\n2017-07-25 11:33:01\n===================================\nPrinting the timestamp for S13\n===================================\n2017-08-08 11:33:01\n===================================\nPrinting the timestamp for S14\n===================================\n2017-08-09 07:31:01\n===================================\nPrinting the timestamp for S15\n===================================\n2017-08-10 07:30:01\n===================================\nPrinting the timestamp for S16\n===================================\n2017-08-10 12:21:01\n===================================\nPrinting the timestamp for S17\n===================================\n2017-08-11 07:39:01\n===================================\nPrinting the timestamp for S2\n===================================\n2017-05-22 07:39:01\n===================================\nPrinting the timestamp for S3\n===================================\n2017-05-24 11:26:01\n===================================\nPrinting the timestamp for S4\n===================================\n2017-06-13 08:57:01\n===================================\nPrinting the timestamp for S5\n===================================\n2017-06-13 12:42:01\n===================================\nPrinting the timestamp for S6\n===================================\n2017-06-14 11:40:01\n===================================\nPrinting the timestamp for S7\n===================================\n2017-07-06 11:30:01\n===================================\nPrinting the timestamp for S8\n===================================\n2017-07-10 11:28:01\n===================================\nPrinting the timestamp for S9\n===================================\n2017-07-11 11:26:01\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/fefespinola/ETHZ_Fall_2020/') #local directory where the script is\n",
    "File_Path = glob2.glob('project_data/WESAD/**/*_readme.txt', recursive=True)\n",
    "for subject_path in File_Path:\n",
    "    start_time = find_label_start_time(subject_path)\n",
    "    print(start_time)"
   ]
  },
  {
   "source": [
    "def render_metric(eval_results, metric_name):\n",
    "    ax = lgb.plot_metric(evals_result, metric=metric_name, figsize=(10, 5))\n",
    "    #plt.show()\n",
    "    plt.savefig('/home/fefespinola/ETHZ_Fall_2020/plots/render_metric_all_ekf_feat.png')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "source": [
    "Plots the 10 top important classification features, i.e. the ones that influence the output the most."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_plot_importance(gbm, importance_type, max_features=10, ignore_zero=True, precision=3):\n",
    "    ax = lgb.plot_importance(gbm, importance_type=importance_type,\n",
    "                             max_num_features=max_features,\n",
    "                             ignore_zero=ignore_zero, figsize=(12, 8),\n",
    "                             precision=precision)\n",
    "    #plt.show()\n",
    "    plt.savefig('/home/fefespinola/ETHZ_Fall_2020/plots/feature_importance_all_ekf_feat.png')\n"
   ]
  },
  {
   "source": [
    "Main function that calls the above functions, determines the relevant data to use (i.e. that within the useful recording periods of baseline, stress and amusement) using the timestampp offsets, assignes the appropriate label to each sample and returns the full data with training samples and the corresponding labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    os.chdir('/home/fefespinola/ETHZ_Fall_2020/') #local directory where the script is\n",
    "    df_all = pd.DataFrame(None)\n",
    "    #relevant_features = pd.DataFrame(None)\n",
    "    File_Path = glob2.glob('project_data/WESAD/**/*_readme.txt', recursive=True)\n",
    "    window_length = 60 # in seconds\n",
    "    window_shift = 0.25 # in seconds\n",
    "    for subject_path in File_Path:\n",
    "        print(subject_path)\n",
    "        print(subject_path.split('/', 3)[2])\n",
    "        ID = subject_path.split('/', 3)[2]\n",
    "        zip_path = glob2.glob('project_data/WESAD/' + ID + '/*_Data.zip')[0]\n",
    "        print(zip_path)\n",
    "        features = get_features_per_subject(zip_path, window_length)\n",
    "        features.index.name = 'timedata'\n",
    "        E4Time = features.index[0]\n",
    "        print(E4Time)\n",
    "        StartingTime = find_label_start_time(subject_path)\n",
    "        print(StartingTime)\n",
    "        labels_times = find_label_timestamps(subject_path, StartingTime)\n",
    "        #features.index.tz_localize(tz='UTC')\n",
    "        relevant_features = features.loc[\n",
    "            ((features.index.tz_localize(tz=None) >= labels_times['Base'][0]) & (features.index.tz_localize(tz=None) <= labels_times['Base'][1])) \n",
    "            | ((features.index.tz_localize(tz=None) >= labels_times['Fun'][0]) & (features.index.tz_localize(tz=None) <= labels_times['Fun'][1])) \n",
    "            | ((features.index.tz_localize(tz=None) >= labels_times['TSST'][0]) & (features.index.tz_localize(tz=None) <= labels_times['TSST'][1]))]\n",
    "\n",
    "        relevant_features.insert(0, 'ID', ID)\n",
    "        relevant_features['label'] = np.zeros(len(relevant_features))\n",
    "        relevant_features.loc[(relevant_features.index.tz_localize(tz=None)>=labels_times['Fun'][0]) &\n",
    "                                (relevant_features.index.tz_localize(tz=None)<=labels_times['Fun'][1]), 'label'] = labels_times['Fun'][2]\n",
    "        relevant_features.loc[(relevant_features.index.tz_localize(tz=None)>=labels_times['TSST'][0]) & \n",
    "                            (relevant_features.index.tz_localize(tz=None)<=labels_times['TSST'][1]), 'label'] = labels_times['TSST'][2]\n",
    "\n",
    "        # concatenate all subjects and add IDs\n",
    "        df_all = pd.concat((df_all, relevant_features))\n",
    "    \n",
    "    print(df_all)\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "source": [
    "This function generates and saves feature matrices for the individual physiological signals "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_subset_features(df_all, feature_name: str, eda_method:str='lpf'):\n",
    "    \n",
    "    if feature_name=='physio':\n",
    "        small_df = df_all.loc[:, df_all.columns.str.startswith('hrv')&df_all.columns.str.startswith   ('eda')&df_all.columns.str.startswith('bvp')&df_all.columns.str.startswith('temp')]\n",
    "        filename = 'features_all_' + features_name +'_' + eda_method + '_feat.csv'\n",
    "    else:\n",
    "        small_df = df_all.loc[:, df_all.columns.str.startswith(feature_name)]\n",
    "        if feature_name=='eda':\n",
    "            filename = 'features_all_' + features_name +'_' + eda_method + '_feat.csv'\n",
    "        else:\n",
    "            filename = 'features_all_' + features_name + '_feat.csv'\n",
    "    small_df.to_csv(filename)\n"
   ]
  },
  {
   "source": [
    "The following function retrieves the correct training and testing data for LOSO cross-validation. It also deals with missing data (inf and nan), and scales the features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_train_valid_data(df_all, cv_subject):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #training data\n",
    "    X_train = df_all.loc[df_all['ID']!=cv_subject]  # 500 entities, each contains 10 features\n",
    "    X_train = X_train.iloc[:, 1:len(df_all.columns)-1]\n",
    "    X_train = X_train.replace([np.nan, np.inf, -np.inf], -1000)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    y_train = df_all.loc[df_all['ID']!=cv_subject, ['label']]  # binary target\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    #validation data\n",
    "    X_test = df_all.loc[df_all['ID']==cv_subject]  # 500 entities, each contains 10 features\n",
    "    X_test = X_test.iloc[:, 1:len(df_all.columns)-1]\n",
    "    X_test = X_test.replace([np.nan, np.inf, -np.inf], -1000)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_test = df_all.loc[df_all['ID']==cv_subject, ['label']]   # binary target\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    return X_train, y_train, train_data, X_test, y_test, test_data\n",
    " "
   ]
  },
  {
   "source": [
    "Run the evaluation script to retrieve the labeled data and train classifier to output f1-score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "project_data/WESAD/S10/S10_readme.txt\nS10\nproject_data/WESAD/S10/S10_E4_Data.zip\nReading files\nCalculating EDA features\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'flirt.eda.preprocessing' has no attribute 'CvxEDA'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-397454965431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/fefespinola/ETHZ_Fall_2020/features_all_eda_ekf_leda.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/fefespinola/ETHZ_Fall_2020/features_all_eda_ekf_leda.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timedata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a1aa5724b44e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_data/WESAD/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mID\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*_Data.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_per_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'timedata'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mE4Time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-708bd86ec223>\u001b[0m in \u001b[0;36mget_features_per_subject\u001b[0;34m(path, window_length)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                       \u001b[0mbvp_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       \u001b[0mtemp_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                       debug = True)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ETHZ_Fall_2020/flirt-1/flirt/simple/empatica.py\u001b[0m in \u001b[0;36mget_features_for_empatica_archive\u001b[0;34m(zip_file_path, window_length, window_step_size, hrv_features, eda_features, acc_features, bvp_features, temp_features, debug)\u001b[0m\n\u001b[1;32m     92\u001b[0m                                                              \u001b[0mwindow_step_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_step_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                                              \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meda_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendedKalmanFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                                                              \u001b[0msignal_decomposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meda_preprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCvxEDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                                                              scr_features=eda_preprocess.ComputeMITPeaks()).add_prefix('eda_')\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'flirt.eda.preprocessing' has no attribute 'CvxEDA'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_all = main()\n",
    "    df_all.to_csv('/home/fefespinola/ETHZ_Fall_2020/features_all_eda_ekf_leda.csv')\n",
    "    df_all = pd.read_csv('/home/fefespinola/ETHZ_Fall_2020/features_all_eda_ekf_leda.csv')\n",
    "    df_all.set_index('timedata', inplace=True)\n",
    "    #df_all = df_all.loc[:, ~df_all.columns.str.startswith('hrv')]\n",
    "    print(df_all)\n",
    "    ID=df_all.ID\n",
    "    print(ID.unique())\n",
    "\n",
    "    ### for binary classification uncomment line below \n",
    "    #df_all['label'].replace(2, 0, inplace=True)\n",
    "    #print('===== BINARY ====')\n",
    "\n",
    "    print('---start classification---')\n",
    "\n",
    "    df_all.round(4)\n",
    "    df = df_all.replace([np.inf, -np.inf], np.nan) # np.inf leads to problems with some techniques\n",
    "\n",
    "    # Clean columns that contain a lot of nan values \n",
    "    print(len(df), len(df.columns))\n",
    "    df = df.dropna(axis=1, thresh=int(len(df)*0.8))\n",
    "    print(len(df), len(df.columns))\n",
    "    print('Columns dropped: ', df_all.drop(df.columns, axis=1).columns.values)\n",
    "\n",
    "    stats = []\n",
    "\n",
    "    cv = model_selection.LeaveOneGroupOut()\n",
    "\n",
    "    X = df.drop(columns=['label', 'ID'])\n",
    "    y = df['label'].astype('int')\n",
    "    groups = df['ID']\n",
    "    print(\"running %d-fold CV...\" % (cv.get_n_splits(X, y, groups)))\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for train_index, test_index in cv.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #### for binary classification uncomment line below\n",
    "        #params = {'objective': 'binary', 'is_unbalance': True}\n",
    "        params = {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class':3,  'is_unbalance': True}\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        stats.append({\n",
    "            'f1': metrics.f1_score(y_test, y_pred, average=\"macro\")})\n",
    "            \n",
    "        #print(metrics.classification_report(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    stats = pd.DataFrame(stats)\n",
    "    print(stats.f1.mean())\n",
    "\n",
    "    '''\n",
    "    #parameters\n",
    "    param = {'metric': 'auc_mu', 'learning_rate': 0.01, 'num_leaves': 31, 'is_unbalance':True,\n",
    "        'verbose': 1, 'objective':'multiclass', 'num_class':3, 'lambda_l1':0, 'force_col_wise':True}\n",
    "    \n",
    "    subjects = ['S2', 'S3', 'S4', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17']\n",
    "\n",
    "    ##### Start Classification\n",
    "    f1_tot = 0\n",
    "    f1_dict = {}\n",
    "    #data with validation set\n",
    "    for subj in subjects:\n",
    "        # get data\n",
    "        print('===Training for LOSO ', subj, '===')\n",
    "        _, _, train_data, X_test, y_test, test_data = __get_train_valid_data(df_all, subj)\n",
    "    \n",
    "        evals_result = {}  # to record eval results for plotting\n",
    "        \n",
    "        #train normally\n",
    "        bst_norm = lgb.train(param, train_data, num_boost_round=550, valid_sets=[train_data, test_data],                        evals_result=evals_result, verbose_eval=10)\n",
    "\n",
    "        best_iteration = np.argmax(evals_result['valid_1']['auc_mu'][2:]) + 1\n",
    "        print ('best iter', best_iteration)\n",
    "        y_pred = bst_norm.predict(X_test, num_iteration=best_iteration)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        f1_metric = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_dict[subj] = f1_metric\n",
    "        print(f1_dict)\n",
    "        f1_tot = f1_tot + f1_metric\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "    f1_tot = f1_tot/len(subjects)\n",
    "    print(f1_tot)\n",
    "    #render_metric(evals_result, param['metric'])\n",
    "    #render_plot_importance(bst_norm, importance_type='split')\n",
    "    '''"
   ]
  },
  {
   "source": [
    "# Get relevant features\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}